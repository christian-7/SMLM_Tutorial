{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Import the software libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "import bstore.processors as proc\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Outline of steps\n",
    "1. Search the parent directory for all localization files and a build a list of such files\n",
    "2. Define the drift correction processor\n",
    "3. Open a file from the list\n",
    "4. Perform the drift correction on the file\n",
    "  * If the correction was not good, go back to step 2\n",
    "4. Save the results\n",
    "5. Repeat from step 1\n",
    "\n",
    "Tutorial: https://github.com/kmdouglass/bstore/blob/master/examples/Fiducial-based%20Drift%20Correction.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Search the parent directory and make a list of localization files\n",
    "We will start by searching a parent directory and its subdirectories for all the localization files, i.e. those files that end in `locResults.dat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "parentDirectory   = Path('X:/to_analyze/2018-03-01_mitotic_humanCent_Cep152_Sas6/locResults/')\n",
    "localizationFiles = parentDirectory.glob('**/*A647*Localizations.csv')\n",
    "locResultFiles    = sorted(localizationFiles)\n",
    "\n",
    "# How many files are there? \n",
    "print(len(locResultFiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   (   WindowsPath('X:/to_analyze/2018-03-01_mitotic_humanCent_Cep152_Sas6/locResults/Sas6_A647_10_1/Sas6_A647_10_1_MMStack_1_Localizations.csv'),\n",
      "        0),\n",
      "    (   WindowsPath('X:/to_analyze/2018-03-01_mitotic_humanCent_Cep152_Sas6/locResults/Sas6_A647_11_1/Sas6_A647_11_1_MMStack_1_Localizations.csv'),\n",
      "        1),\n",
      "    (   WindowsPath('X:/to_analyze/2018-03-01_mitotic_humanCent_Cep152_Sas6/locResults/Sas6_A647_14_1/Sas6_A647_14_1_MMStack_1_Localizations.csv'),\n",
      "        2),\n",
      "    (   WindowsPath('X:/to_analyze/2018-03-01_mitotic_humanCent_Cep152_Sas6/locResults/Sas6_A647_15_1/Sas6_A647_15_1_MMStack_1_Localizations.csv'),\n",
      "        3),\n",
      "    (   WindowsPath('X:/to_analyze/2018-03-01_mitotic_humanCent_Cep152_Sas6/locResults/Sas6_A647_16_1/Sas6_A647_16_1_MMStack_1_Localizations.csv'),\n",
      "        4),\n",
      "    (   WindowsPath('X:/to_analyze/2018-03-01_mitotic_humanCent_Cep152_Sas6/locResults/Sas6_A647_17_1/Sas6_A647_17_1_MMStack_1_Localizations.csv'),\n",
      "        5),\n",
      "    (   WindowsPath('X:/to_analyze/2018-03-01_mitotic_humanCent_Cep152_Sas6/locResults/Sas6_A647_1_1/Sas6_A647_1_1_MMStack_1_Localizations.csv'),\n",
      "        6),\n",
      "    (   WindowsPath('X:/to_analyze/2018-03-01_mitotic_humanCent_Cep152_Sas6/locResults/Sas6_A647_2_1/Sas6_A647_2_1_MMStack_1_Localizations.csv'),\n",
      "        7),\n",
      "    (   WindowsPath('X:/to_analyze/2018-03-01_mitotic_humanCent_Cep152_Sas6/locResults/Sas6_A647_3_1/Sas6_A647_3_1_MMStack_1_Localizations.csv'),\n",
      "        8),\n",
      "    (   WindowsPath('X:/to_analyze/2018-03-01_mitotic_humanCent_Cep152_Sas6/locResults/Sas6_A647_4_1/Sas6_A647_4_1_MMStack_1_Localizations.csv'),\n",
      "        9),\n",
      "    (   WindowsPath('X:/to_analyze/2018-03-01_mitotic_humanCent_Cep152_Sas6/locResults/Sas6_A647_5_1/Sas6_A647_5_1_MMStack_1_Localizations.csv'),\n",
      "        10),\n",
      "    (   WindowsPath('X:/to_analyze/2018-03-01_mitotic_humanCent_Cep152_Sas6/locResults/Sas6_A647_6_1/Sas6_A647_6_1_MMStack_1_Localizations.csv'),\n",
      "        11),\n",
      "    (   WindowsPath('X:/to_analyze/2018-03-01_mitotic_humanCent_Cep152_Sas6/locResults/Sas6_A647_7_1/Sas6_A647_7_1_MMStack_1_Localizations.csv'),\n",
      "        12),\n",
      "    (   WindowsPath('X:/to_analyze/2018-03-01_mitotic_humanCent_Cep152_Sas6/locResults/Sas6_A647_8_1/Sas6_A647_8_1_MMStack_1_Localizations.csv'),\n",
      "        13),\n",
      "    (   WindowsPath('X:/to_analyze/2018-03-01_mitotic_humanCent_Cep152_Sas6/locResults/Sas6_A647_9_1/Sas6_A647_9_1_MMStack_1_Localizations.csv'),\n",
      "        14)]\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(list(zip(locResultFiles, range(len(locResultFiles)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Define the drift correction processor\n",
    "This part is the same as in Tutorial 1. At the end of processing for each file, return to this code block and start running the blocks again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\\to_analyze\\2018-03-01_mitotic_humanCent_Cep152_Sas6\\locResults\\Sas6_A647_4_1\\Sas6_A647_4_1_MMStack_1_Localizations.csv\n"
     ]
    }
   ],
   "source": [
    "plt.close('all')\n",
    "# Set the input and output files\n",
    "# Up to and including are 26 finished\n",
    "currentFile = locResultFiles[9] # Increment this when done dedrifting a dataset\n",
    "outputFile  = currentFile.parent / Path(currentFile.stem + '_DC' + currentFile.suffix)\n",
    "\n",
    "# Create the FiducialDriftCorrect processor and set its properties.\n",
    "dc = proc.FiducialDriftCorrect(coordCols = ['x [nm]', 'y [nm]'])\n",
    "dc.driftComputer.smoothingWindowSize = 800\n",
    "dc.driftComputer.smoothingFilterSize = 200\n",
    "\n",
    "clean = proc.CleanUp()\n",
    "\n",
    "# Open a file and clean it up\n",
    "with open(str(currentFile), 'r') as file:\n",
    "    df = pd.read_csv(file, sep = ',')\n",
    "    \n",
    "# Clean up the data\n",
    "df = clean(df)\n",
    "\n",
    "print(str(currentFile))\n",
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing spline fits...\n"
     ]
    }
   ],
   "source": [
    "corrdf = dc(df)\n",
    "dc.driftComputer.plotFiducials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing spline fits...\n"
     ]
    }
   ],
   "source": [
    "plt.close('all')\n",
    "# Skip this cell if you don't need to adjust the fits\n",
    "dc.interactiveSearch = False\n",
    "\n",
    "# Modify these if needed to adjust the fits\n",
    "dc.driftComputer.useTrajectories      = [0,1,2,4] # Set to [] if you want to use all fiducials\n",
    "dc.driftComputer.zeroFrame            = 1000  # Set to 1000 by default\n",
    "dc.driftComputer.smoothingWindowSize  = 1200\n",
    "dc.driftComputer.smoothingFilterSize  = 300\n",
    "dc.driftComputer.maxRadius = 500\n",
    "\n",
    "# processed_df = dc(df)\n",
    "corrdf = dc(df)\n",
    "dc.driftComputer.plotFiducials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x [nm]</th>\n",
       "      <th>y [nm]</th>\n",
       "      <th>frame</th>\n",
       "      <th>uncertainty [nm]</th>\n",
       "      <th>intensity [photon]</th>\n",
       "      <th>offset [photon]</th>\n",
       "      <th>loglikelihood</th>\n",
       "      <th>sigma_x [nm]</th>\n",
       "      <th>sigma_y [nm]</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>613.014707</td>\n",
       "      <td>72185.173791</td>\n",
       "      <td>100</td>\n",
       "      <td>13.7830</td>\n",
       "      <td>1026.2</td>\n",
       "      <td>70.240</td>\n",
       "      <td>721.21</td>\n",
       "      <td>212.70</td>\n",
       "      <td>132.37</td>\n",
       "      <td>-0.874707</td>\n",
       "      <td>-3.173791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2130.774707</td>\n",
       "      <td>22864.173791</td>\n",
       "      <td>100</td>\n",
       "      <td>7.1423</td>\n",
       "      <td>1766.2</td>\n",
       "      <td>72.012</td>\n",
       "      <td>798.98</td>\n",
       "      <td>186.97</td>\n",
       "      <td>121.56</td>\n",
       "      <td>-0.874707</td>\n",
       "      <td>-3.173791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3358.574707</td>\n",
       "      <td>29735.173791</td>\n",
       "      <td>100</td>\n",
       "      <td>17.0510</td>\n",
       "      <td>3266.9</td>\n",
       "      <td>79.543</td>\n",
       "      <td>897.42</td>\n",
       "      <td>426.40</td>\n",
       "      <td>265.74</td>\n",
       "      <td>-0.874707</td>\n",
       "      <td>-3.173791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4546.074707</td>\n",
       "      <td>28304.173791</td>\n",
       "      <td>100</td>\n",
       "      <td>11.9670</td>\n",
       "      <td>1578.1</td>\n",
       "      <td>77.641</td>\n",
       "      <td>782.05</td>\n",
       "      <td>221.40</td>\n",
       "      <td>171.73</td>\n",
       "      <td>-0.874707</td>\n",
       "      <td>-3.173791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19152.874707</td>\n",
       "      <td>2941.473791</td>\n",
       "      <td>100</td>\n",
       "      <td>12.2150</td>\n",
       "      <td>1420.6</td>\n",
       "      <td>75.453</td>\n",
       "      <td>940.35</td>\n",
       "      <td>246.34</td>\n",
       "      <td>128.29</td>\n",
       "      <td>-0.874707</td>\n",
       "      <td>-3.173791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x [nm]        y [nm]  frame  uncertainty [nm]  intensity [photon]  \\\n",
       "0    613.014707  72185.173791    100           13.7830              1026.2   \n",
       "1   2130.774707  22864.173791    100            7.1423              1766.2   \n",
       "2   3358.574707  29735.173791    100           17.0510              3266.9   \n",
       "3   4546.074707  28304.173791    100           11.9670              1578.1   \n",
       "4  19152.874707   2941.473791    100           12.2150              1420.6   \n",
       "\n",
       "   offset [photon]  loglikelihood  sigma_x [nm]  sigma_y [nm]        dx  \\\n",
       "0           70.240         721.21        212.70        132.37 -0.874707   \n",
       "1           72.012         798.98        186.97        121.56 -0.874707   \n",
       "2           79.543         897.42        426.40        265.74 -0.874707   \n",
       "3           77.641         782.05        221.40        171.73 -0.874707   \n",
       "4           75.453         940.35        246.34        128.29 -0.874707   \n",
       "\n",
       "         dy  \n",
       "0 -3.173791  \n",
       "1 -3.173791  \n",
       "2 -3.173791  \n",
       "3 -3.173791  \n",
       "4 -3.173791  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Run this only if no good fiducials are found.\n",
    "#dc.driftComputer.fiducialLocs = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\\to_analyze\\2018-03-01_mitotic_humanCent_Cep152_Sas6\\locResults\\Sas6_A647_4_1\\Sas6_A647_4_1_MMStack_1_Localizations_DC.csv\n",
      "X:\\to_analyze\\2018-03-01_mitotic_humanCent_Cep152_Sas6\\locResults\\Sas6_A647_4_1\\Sas6_A647_4_1_MMStack_1_Localizations_Avg.csv\n",
      "X:\\to_analyze\\2018-03-01_mitotic_humanCent_Cep152_Sas6\\locResults\\Sas6_A647_4_1\\Sas6_A647_4_1_MMStack_1_Localizations_Fid.csv\n"
     ]
    }
   ],
   "source": [
    "saveTrajectories = True\n",
    "# If no fiducials were found, append '_DCX' to the filename;\n",
    "# Otherwise, append '_DC'\n",
    "if dc.driftComputer.fiducialLocs is None:\n",
    "    with open(str(currentFile), 'r') as file:\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "    corrdf = clean(df)\n",
    "    outputFile = currentFile.parent / Path(currentFile.stem + '_DCX' + currentFile.suffix)\n",
    "    saveTrajectories = False\n",
    "    \n",
    "print(str(outputFile))\n",
    "\n",
    "# Save the data\n",
    "with open(str(outputFile), 'w') as file:\n",
    "    corrdf.to_csv(file, index=False)\n",
    "    \n",
    "if saveTrajectories:\n",
    "    # Save the average trajectory\n",
    "    #outputTrajectoryFile = currentFile.parent / Path(currentFile.stem + '_AverageFiducialTrajectory' + currentFile.suffix)\n",
    "    outputTrajectoryFile = currentFile.parent / Path(currentFile.stem + '_Avg' + currentFile.suffix)\n",
    "    with open(str(outputTrajectoryFile), 'w') as file:\n",
    "        dc.driftTrajectory.to_csv(file, index = True)\n",
    "    print(str(outputTrajectoryFile))\n",
    "    \n",
    "    # Save the individual trajectories\n",
    "    #outputTrajectoryFile = currentFile.parent / Path(currentFile.stem + '_FiducialTrajectories' + currentFile.suffix)\n",
    "    outputTrajectoryFile = currentFile.parent / Path(currentFile.stem + '_Fid' + currentFile.suffix)\n",
    "    #with open(str(outputTrajectoryFile), 'w') as file:\n",
    "    #   dc.driftComputer.fiducialLocs.loc[(slice(None), dc.driftComputer.useTrajectories), :].to_csv(file, index = True)\n",
    "    #print(str(outputTrajectoryFile))\n",
    "    \n",
    "    with open(str(outputTrajectoryFile), 'w') as file:\n",
    "            if dc.driftComputer.useTrajectories: # Important because the.loc will return None if all trajectories are used \n",
    "                dc.driftComputer.fiducialLocs.loc[(slice(None),dc.driftComputer.useTrajectories), :].to_csv(file, index = True)\n",
    "            else:\n",
    "                dc.driftComputer.fiducialLocs.to_csv(file, index = True)\n",
    "    print(str(outputTrajectoryFile))\n",
    "    \n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now you can cycle back up to the beginning and increase the index locResultFiles array by one and repeat the process in this notebook."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:bstore]",
   "language": "python",
   "name": "conda-env-bstore-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
