{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example notebook demonstrates how a normal processing pipleline works without batch processing. The outline of processing steps are as follows:\n",
    "\n",
    "1. Clean up the data\n",
    "2. Perform drift correction\n",
    "3. Apply light filtering to the data to prepare for merging\n",
    "4. Merge localizations into one\n",
    "5. Apply any final filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt4Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "from bstore import processors as proc\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Press TAB inside the quotation marks\n",
    "filePath = Path('X:/Christian-Sieben/data_HTP/locResults/Cos7_PCSIR_bTub_10ms_PBS_1/Cos7_PCSIR_bTub_10ms_PBS_1_MMStack_Pos0_locResults.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laboleb\\Anaconda3\\envs\\DataSTORM\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2723: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# str() converts the Path to a string\n",
    "# 'r' means to open the file in read-mode\n",
    "# df holds the DataFrame returned from pd.read_csv()\n",
    "with open(str(filePath), 'r') as file:\n",
    "    df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleaner = proc.CleanUp()\n",
    "df      = cleaner(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save only cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\\Christian-Sieben\\data_HTP\\locResults\\Cos7_PCSIR_bTub_10ms_PBS_1\\Cos7_PCSIR_bTub_10ms_PBS_1_MMStack_Pos0_locResults_cleaned.dat\n"
     ]
    }
   ],
   "source": [
    "outputFile = filePath.parent /  Path(filePath.stem + '_cleaned' + filePath.suffix)\n",
    "print(outputFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(str(outputFile), 'w') as file:\n",
    "    df.to_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proceed with drift correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corrector = proc.FiducialDriftCorrect(minFracFiducialLength = 0.75, # Fiducials must span 75% of number of frames\n",
    "                                      interactiveSearch     = True, # Select fiducials by eye\n",
    "                                      noLinking             = True, # Do not perform Crocker-Grier linking\n",
    "                                      noClustering          = True) # Do not spatially cluster fiducials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the corrector is run, it will display a 2D histogram image. You may zoom in and out of regions and draw a rectangle around areas with large counts. Areas with counts that are approximately equal to the number of frames are likely to be fiducials. There is a fiducial in this dataset in three bins around (x = 28, y = 55.5).\n",
    "\n",
    "With the selection rectangle around a region, press `SPACE` to add the region to the list of areas to search for fiducials. Press `r` if you want to reset the regions to empty. When you are done, simply close the window.\n",
    "\n",
    "If no region is selected, the fiducial search will be performed over the whole set of localizations, which can either be slow or lead to completely wrong results if linking and clustering are turned off.\n",
    "\n",
    "Also note that the corrector removes fiducials, so it is best to save the output to another DataFrame, in this case `corrDF`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corrDF = corrector(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the quality of the drift correction curves using `plotFiducials()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corrector.plotFiducials()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not necessary for this dataset, but if the drift correction could be improved, we can adjust some of the smoothing parameters and rerun the drift correction. For this example, we'll turn on linking and throw out trajectories shorter than ten consecutive frames. Additionally, we'll shrink the size of the smoothing window and filters to better capture changes in the fiducial trajectory. There are a few parameters for linking and clustering, but we'll leave them at their defaults.\n",
    "\n",
    "Note that clustering the fiducials can often help get rid of noisy points. However, DBSCAN breaks down if the fiducials are more than about 50,000 frames, so it is preferable to turn it off if you have a long fiducial track as in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corrector = proc.FiducialDriftCorrect(minFracFiducialLength = 0.75,   # Fiducials must span 75% of number of frames\n",
    "                                      interactiveSearch     = True,   # Select fiducials bye eye\n",
    "                                      noLinking             = False,  # Perform Crocker-Grier linking\n",
    "                                      noClustering          = True,   # Perform DBSCAN to cluster fiducials\n",
    "                                      smoothingWindowSize   = 750,    # Set the moving window size for smoothing\n",
    "                                      smoothingFilterSize   = 100)    # Set Gaussian filter std. dev. for smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# corrDF = corrector(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# corrector.plotFiducials()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now investigate the corrected localizations. The x and y columns now contain the corrected localizations. `dx` and `dy` contain the amount of the correction. To get the original data back, one can simply add `dx` to `x` and the same for `y`.\n",
    "\n",
    "Note that the new count is less than the original one. This is because the drift correction removed localizations belonging to the fiducial marker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# corrDF.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering the data\n",
    "At this point, we can now filter the data by setting criteria on the columns. First we define the filters. After that, we simply apply them in reverse order to the DataFrame to get the filtered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filter1 = proc.Filter('sigma [nm]', '<', 200)\n",
    "filter2 = proc.Filter('sigma [nm]', '>', 100)\n",
    "filter3 = proc.Filter('loglikelihood', '<', 400)\n",
    "\n",
    "fcDF = filter3(filter2(filter1(corrDF))) # First filter1 is applied, then filter2 is applied.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fcDF.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save only drift corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputFile = filePath.parent /  Path(filePath.stem + '_DC' + filePath.suffix)\n",
    "print(outputFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(str(outputFile), 'w') as file:\n",
    "    fcDF.to_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging localizations\n",
    "The last step in the analysis pipeline typically involves merging localizations that are on for several frames into one. This is performed by the Crocker-Grier algorithm in trackpy, but all you have to worry about it defining a Merge processor and applying it to the DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merger = proc.Merge(tOff            = 1,  # Number of frames that a molecule can be missing and still be part of a track\n",
    "                    mergeRadius     = 40) # Maximum distance between successive molecules\n",
    "\n",
    "mfcDF = merger(fcDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mfcDF.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final filtering and saving\n",
    "At this point, the data may be filtered once more in the same manner as above. Let's skip this part and save the data to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputFile = filePath.parent /  Path(filePath.stem + '_DC_Merged' + filePath.suffix)\n",
    "print(outputFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(str(outputFile), 'w') as file:\n",
    "    mfcDF.to_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save only drift corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
