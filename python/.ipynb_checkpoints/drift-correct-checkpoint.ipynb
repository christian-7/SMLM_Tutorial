{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the software libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "import bstore.processors as proc\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline of steps\n",
    "1. Search the parent directory for all localization files and a build a list of such files\n",
    "2. Define the drift correction processor\n",
    "3. Open a file from the list\n",
    "4. Perform the drift correction on the file\n",
    "  * If the correction was not good, go back to step 2\n",
    "4. Save the results\n",
    "5. Repeat from step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search the parent directory and make a list of localization files\n",
    "We will start by searching a parent directory and its subdirectories for all the localization files, i.e. those files that end in `locResults.dat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "parentDirectory   = Path('E:/to_analyze/2017-02-14_multiColor_Tests/locResults')\n",
    "localizationFiles = parentDirectory.glob('**/*locResults.dat')\n",
    "locResultFiles    = sorted(localizationFiles)\n",
    "\n",
    "# How many files are there? \n",
    "print(len(locResultFiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   (   WindowsPath('E:/to_analyze/2017-02-14_multiColor_Tests/locResults/A647_DL755_Ch642_FOV_1/A647_DL755_Ch642_FOV_1_MMStack_1_locResults.dat'),\n",
      "        0),\n",
      "    (   WindowsPath('E:/to_analyze/2017-02-14_multiColor_Tests/locResults/A647_DL755_Ch647_FOV_1/A647_DL755_Ch647_FOV_1_MMStack_1_locResults.dat'),\n",
      "        1),\n",
      "    (   WindowsPath('E:/to_analyze/2017-02-14_multiColor_Tests/locResults/A647_DL755_Ch755_FOV_1/A647_DL755_Ch755_FOV_1_MMStack_1_locResults.dat'),\n",
      "        2),\n",
      "    (   WindowsPath('E:/to_analyze/2017-02-14_multiColor_Tests/locResults/A647_DL755_Ch755_FOV_2/A647_DL755_Ch755_FOV_2_MMStack_1_locResults.dat'),\n",
      "        3),\n",
      "    (   WindowsPath('E:/to_analyze/2017-02-14_multiColor_Tests/locResults/A647_DL755_Ch755_FOV_3/A647_DL755_Ch755_FOV_3_MMStack_1_locResults.dat'),\n",
      "        4),\n",
      "    (   WindowsPath('E:/to_analyze/2017-02-14_multiColor_Tests/locResults/A647_DL755_Ch755_FOV_4/A647_DL755_Ch755_FOV_4_MMStack_1_locResults.dat'),\n",
      "        5),\n",
      "    (   WindowsPath('E:/to_analyze/2017-02-14_multiColor_Tests/locResults/DyLight755_FOV_1/DyLight755_FOV_1_MMStack_1_locResults.dat'),\n",
      "        6),\n",
      "    (   WindowsPath('E:/to_analyze/2017-02-14_multiColor_Tests/locResults/PA549_A647_Ch_549_FOV_1/PA549_A647_Ch_549_FOV_1_MMStack_1_locResults.dat'),\n",
      "        7),\n",
      "    (   WindowsPath('E:/to_analyze/2017-02-14_multiColor_Tests/locResults/PA549_A647_Ch_549_FOV_2/PA549_A647_Ch_549_FOV_2_MMStack_1_locResults.dat'),\n",
      "        8),\n",
      "    (   WindowsPath('E:/to_analyze/2017-02-14_multiColor_Tests/locResults/PA549_A647_Ch_642_FOV_1/PA549_A647_Ch_642_FOV_1_MMStack_1_locResults.dat'),\n",
      "        9),\n",
      "    (   WindowsPath('E:/to_analyze/2017-02-14_multiColor_Tests/locResults/PA549_A647_Ch_647_FOV_1/PA549_A647_Ch_647_FOV_1_MMStack_1_locResults.dat'),\n",
      "        10),\n",
      "    (   WindowsPath('E:/to_analyze/2017-02-14_multiColor_Tests/locResults/PA549_FOV_1/PA549_FOV_1_MMStack_1_locResults.dat'),\n",
      "        11),\n",
      "    (   WindowsPath('E:/to_analyze/2017-02-14_multiColor_Tests/locResults/PA549_FOV_2/PA549_FOV_2_MMStack_1_locResults.dat'),\n",
      "        12),\n",
      "    (   WindowsPath('E:/to_analyze/2017-02-14_multiColor_Tests/locResults/PA549_FOV_3/PA549_FOV_3_MMStack_1_locResults.dat'),\n",
      "        13)]\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(list(zip(locResultFiles, range(len(locResultFiles)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the drift correction processor\n",
    "This part is the same as in Tutorial 1. At the end of processing for each file, return to this code block and start running the blocks again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laboleb\\Anaconda3\\envs\\bstore1\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\to_analyze\\2017-02-14_multiColor_Tests\\locResults\\A647_DL755_Ch647_FOV_1\\A647_DL755_Ch647_FOV_1_MMStack_1_locResults.dat\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x [nm]</th>\n",
       "      <th>y [nm]</th>\n",
       "      <th>z [nm]</th>\n",
       "      <th>frame</th>\n",
       "      <th>uncertainty [nm]</th>\n",
       "      <th>intensity [photon]</th>\n",
       "      <th>offset [photon]</th>\n",
       "      <th>loglikelihood</th>\n",
       "      <th>sigma [nm]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.287343e+06</td>\n",
       "      <td>5.287343e+06</td>\n",
       "      <td>5287343.0</td>\n",
       "      <td>5.287343e+06</td>\n",
       "      <td>5.287343e+06</td>\n",
       "      <td>5.287343e+06</td>\n",
       "      <td>5.287343e+06</td>\n",
       "      <td>5.287343e+06</td>\n",
       "      <td>5.287343e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.505822e+04</td>\n",
       "      <td>3.390954e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.902171e+03</td>\n",
       "      <td>5.275034e+14</td>\n",
       "      <td>1.817649e+03</td>\n",
       "      <td>1.676529e+02</td>\n",
       "      <td>1.007296e+02</td>\n",
       "      <td>1.569378e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.931448e+04</td>\n",
       "      <td>2.086314e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.830768e+03</td>\n",
       "      <td>6.754894e+17</td>\n",
       "      <td>8.514073e+02</td>\n",
       "      <td>1.668241e+01</td>\n",
       "      <td>8.176284e+01</td>\n",
       "      <td>2.182665e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.190500e+00</td>\n",
       "      <td>3.162700e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.122400e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.106200e+02</td>\n",
       "      <td>1.921300e+01</td>\n",
       "      <td>5.300000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.040900e+04</td>\n",
       "      <td>1.406800e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.405000e+03</td>\n",
       "      <td>9.090200e+00</td>\n",
       "      <td>1.246900e+03</td>\n",
       "      <td>1.570700e+02</td>\n",
       "      <td>7.100100e+01</td>\n",
       "      <td>1.438600e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.369200e+04</td>\n",
       "      <td>3.392200e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.339000e+03</td>\n",
       "      <td>1.131000e+01</td>\n",
       "      <td>1.642200e+03</td>\n",
       "      <td>1.655400e+02</td>\n",
       "      <td>8.841400e+01</td>\n",
       "      <td>1.561000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.227000e+04</td>\n",
       "      <td>5.361900e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.105000e+03</td>\n",
       "      <td>1.368200e+01</td>\n",
       "      <td>2.174100e+03</td>\n",
       "      <td>1.751300e+02</td>\n",
       "      <td>1.131200e+02</td>\n",
       "      <td>1.693300e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.773300e+04</td>\n",
       "      <td>6.773400e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.999000e+03</td>\n",
       "      <td>1.160400e+21</td>\n",
       "      <td>3.561900e+04</td>\n",
       "      <td>9.326000e+02</td>\n",
       "      <td>2.274800e+04</td>\n",
       "      <td>3.710000e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             x [nm]        y [nm]     z [nm]         frame  uncertainty [nm]  \\\n",
       "count  5.287343e+06  5.287343e+06  5287343.0  5.287343e+06      5.287343e+06   \n",
       "mean   3.505822e+04  3.390954e+04        0.0  3.902171e+03      5.275034e+14   \n",
       "std    1.931448e+04  2.086314e+04        0.0  2.830768e+03      6.754894e+17   \n",
       "min    1.190500e+00  3.162700e-01        0.0  1.000000e+02      1.122400e+00   \n",
       "25%    2.040900e+04  1.406800e+04        0.0  1.405000e+03      9.090200e+00   \n",
       "50%    3.369200e+04  3.392200e+04        0.0  3.339000e+03      1.131000e+01   \n",
       "75%    5.227000e+04  5.361900e+04        0.0  6.105000e+03      1.368200e+01   \n",
       "max    6.773300e+04  6.773400e+04        0.0  9.999000e+03      1.160400e+21   \n",
       "\n",
       "       intensity [photon]  offset [photon]  loglikelihood    sigma [nm]  \n",
       "count        5.287343e+06     5.287343e+06   5.287343e+06  5.287343e+06  \n",
       "mean         1.817649e+03     1.676529e+02   1.007296e+02  1.569378e+02  \n",
       "std          8.514073e+02     1.668241e+01   8.176284e+01  2.182665e+01  \n",
       "min          1.000000e+00     1.106200e+02   1.921300e+01  5.300000e+01  \n",
       "25%          1.246900e+03     1.570700e+02   7.100100e+01  1.438600e+02  \n",
       "50%          1.642200e+03     1.655400e+02   8.841400e+01  1.561000e+02  \n",
       "75%          2.174100e+03     1.751300e+02   1.131200e+02  1.693300e+02  \n",
       "max          3.561900e+04     9.326000e+02   2.274800e+04  3.710000e+02  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the input and output files\n",
    "# Up to and including are 26 finished\n",
    "currentFile = locResultFiles[1] # Increment this when done dedrifting a dataset\n",
    "outputFile  = currentFile.parent / Path(currentFile.stem + '_DC' + currentFile.suffix)\n",
    "\n",
    "# Create the FiducialDriftCorrect processor and set its properties.\n",
    "dc = proc.FiducialDriftCorrect(coordCols = ['x [nm]', 'y [nm]'])\n",
    "dc.driftComputer.smoothingWindowSize = 800\n",
    "dc.driftComputer.smoothingFilterSize = 200\n",
    "\n",
    "clean = proc.CleanUp()\n",
    "\n",
    "# Open a file and clean it up\n",
    "with open(str(currentFile), 'r') as file:\n",
    "    df = pd.read_csv(file, sep = ',')\n",
    "    \n",
    "# Clean up the data\n",
    "df = clean(df)\n",
    "\n",
    "print(str(currentFile))\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing spline fits...\n"
     ]
    }
   ],
   "source": [
    "corrdf = dc(df)\n",
    "dc.driftComputer.plotFiducials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing spline fits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laboleb\\Anaconda3\\envs\\bstore1\\lib\\site-packages\\bstore\\processors.py:794: UserWarning: Could not determine an offset value; setting offsets to zero.\n",
      "  warnings.warn('Could not determine an offset value; '\n"
     ]
    }
   ],
   "source": [
    "# Skip this cell if you don't need to adjust the fits\n",
    "dc.interactiveSearch = False\n",
    "\n",
    "# Modify these if needed to adjust the fits\n",
    "dc.driftComputer.useTrajectories     = [0] # Set to [] if you want to use all fiducials\n",
    "dc.driftComputer.zeroFrame           = 2000  # Set to 1000 by default\n",
    "dc.driftComputer.smoothingWindowSize = 800\n",
    "dc.driftComputer.smoothingFilterSize = 200\n",
    "dc.driftComputer.maxRadius = 60\n",
    "\n",
    "processed_df = dc(df)\n",
    "dc.driftComputer.plotFiducials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this only if no good fiducials are found.\n",
    "#dc.driftComputer.fiducialLocs = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\to_analyze\\2017-02-14_multiColor_Tests\\locResults\\A647_DL755_Ch647_FOV_1\\A647_DL755_Ch647_FOV_1_MMStack_1_locResults_DC.dat\n",
      "E:\\to_analyze\\2017-02-14_multiColor_Tests\\locResults\\A647_DL755_Ch647_FOV_1\\A647_DL755_Ch647_FOV_1_MMStack_1_locResults_Avg.dat\n",
      "E:\\to_analyze\\2017-02-14_multiColor_Tests\\locResults\\A647_DL755_Ch647_FOV_1\\A647_DL755_Ch647_FOV_1_MMStack_1_locResults_Fid.dat\n"
     ]
    }
   ],
   "source": [
    "saveTrajectories = True\n",
    "# If no fiducials were found, append '_DCX' to the filename;\n",
    "# Otherwise, append '_DC'\n",
    "if dc.driftComputer.fiducialLocs is None:\n",
    "    with open(str(currentFile), 'r') as file:\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "    corrdf = clean(df)\n",
    "    outputFile = currentFile.parent / Path(currentFile.stem + '_DCX' + currentFile.suffix)\n",
    "    saveTrajectories = False\n",
    "    \n",
    "print(str(outputFile))\n",
    "\n",
    "# Save the data\n",
    "with open(str(outputFile), 'w') as file:\n",
    "    corrdf.to_csv(file, index=False)\n",
    "    \n",
    "if saveTrajectories:\n",
    "    # Save the average trajectory\n",
    "    #outputTrajectoryFile = currentFile.parent / Path(currentFile.stem + '_AverageFiducialTrajectory' + currentFile.suffix)\n",
    "    outputTrajectoryFile = currentFile.parent / Path(currentFile.stem + '_Avg' + currentFile.suffix)\n",
    "    with open(str(outputTrajectoryFile), 'w') as file:\n",
    "        dc.driftTrajectory.to_csv(file, index = True)\n",
    "    print(str(outputTrajectoryFile))\n",
    "    \n",
    "    # Save the individual trajectories\n",
    "    #outputTrajectoryFile = currentFile.parent / Path(currentFile.stem + '_FiducialTrajectories' + currentFile.suffix)\n",
    "    outputTrajectoryFile = currentFile.parent / Path(currentFile.stem + '_Fid' + currentFile.suffix)\n",
    "    with open(str(outputTrajectoryFile), 'w') as file:\n",
    "        dc.driftComputer.fiducialLocs.loc[(slice(None), dc.driftComputer.useTrajectories), :].to_csv(file, index = True)\n",
    "    print(str(outputTrajectoryFile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can cycle back up to the beginning and increase the index locResultFiles array by one and repeat the process in this notebook."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
